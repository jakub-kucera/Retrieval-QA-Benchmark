{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-04T19:01:49.379565Z",
     "start_time": "2025-01-04T19:01:49.377739Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T20:48:04.511558Z",
     "start_time": "2025-01-04T20:43:37.996214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from clickhouse_connect.driverc.dataconv import datetime\n",
    "\n",
    "from retrieval_qa_benchmark.models import *\n",
    "from retrieval_qa_benchmark.datasets import *\n",
    "from retrieval_qa_benchmark.transforms import *\n",
    "from retrieval_qa_benchmark.evaluators import *\n",
    "from retrieval_qa_benchmark.utils.profiler import PROFILER\n",
    "from retrieval_qa_benchmark.utils.registry import REGISTRY\n",
    "# This is for loading our special yaml configuration with `!include` keyword\n",
    "from retrieval_qa_benchmark.utils.config import load\n",
    "# This is where you can contruct evaluator from config\n",
    "from retrieval_qa_benchmark.utils.factory import EvaluatorFactory\n",
    "\n",
    "# This will print all loaded modules. You can also use it as reference to edit your configuration\n",
    "print(str(REGISTRY))\n",
    "\n",
    "# Choose a configuration to evaluatoe\n",
    "config = load(open(\"config/mmlu.yaml\"))\n",
    "evaluator = EvaluatorFactory.from_config(config).build()\n",
    "\n",
    "# evaluator will return accuracy in float and list of `QAPrediction`\n",
    "acc, result = evaluator()\n",
    "\n",
    "# you can set out_file to generate a JSONL file or write it as your own.\n",
    "# with open(\"some-file-name-to-store-result.jsonl\", \"w\") as f:\n",
    "with open(f\"output_{datetime.now()}.jsonl\", \"w\") as f:\n",
    "    json.dump(\n",
    "        [r.dict() for r in result],\n",
    "       # [r. for r in result],\n",
    "        f,\n",
    "        indent=2,\n",
    "    )"
   ],
   "id": "21964f8e4d42c8a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\thotpot_qa\n",
      "\tmmlu\n",
      "\twikihop\n",
      "Transforms:\n",
      "\tbase\n",
      "\tMRKLAgent\n",
      "\tLangChainSQLAgent\n",
      "\tLangChainListSQLTool\n",
      "\tLangChainInfoSQLTool\n",
      "\tLangChainQuerySQLTool\n",
      "\tLangChainSQLCheckerTool\n",
      "\tFaissESHybrid\n",
      "\tRRFHybrid\n",
      "\tFaiss\n",
      "\tElasticBM25\n",
      "\tMyScale\n",
      "LLMs:\n",
      "\tremote-llm\n",
      "\tgpt\n",
      "\tchatgpt\n",
      "\ttgi\n",
      "Evaluators:\n",
      "\tmcma\n",
      "\tmcsa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/116 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9210f3abbc094af69aa325ce116ddf6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/58 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f3588ace9f742f8b4ec77080809e330"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting dataset...: 100%|██████████| 324/324 [00:00<00:00, 21881.21it/s]\n",
      "Evaluating: 100%|██████████| 324/324 [04:24<00:00,  1.23it/s]\n",
      "\u001B[32m2025-01-04 21:48:04.494\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mretrieval_qa_benchmark.schema.evaluator\u001B[0m:\u001B[36m__call__\u001B[0m:\u001B[36m93\u001B[0m - \u001B[1mEvaluation finished! Executed Evaluator:<class 'retrieval_qa_benchmark.evaluators.mcsa.MCSAEvaluator'> on Dataset:cais/mmlu.prehistory-test with Model:llama3. Score: 66.05%\u001B[0m\n",
      "/var/folders/gm/6zjcwbd164d1v4gmx73009pr0000gp/T/ipykernel_56826/1506113451.py:29: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.3/migration/\n",
      "  [r.dict() for r in result],\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "48d42a7926471fd1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
